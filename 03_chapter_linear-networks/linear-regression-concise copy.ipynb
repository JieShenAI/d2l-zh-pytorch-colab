{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ca6a8b",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 线性回归的简洁实现\n",
    ":label:`sec_linear_concise`\n",
    "\n",
    "在过去的几年里，出于对深度学习强烈的兴趣，\n",
    "许多公司、学者和业余爱好者开发了各种成熟的开源框架。\n",
    "这些框架可以自动化基于梯度的学习算法中重复性的工作。\n",
    "在 :numref:`sec_linear_scratch`中，我们只运用了：\n",
    "（1）通过张量来进行数据存储和线性代数；\n",
    "（2）通过自动微分来计算梯度。\n",
    "实际上，由于数据迭代器、损失函数、优化器和神经网络层很常用，\n",
    "现代深度学习库也为我们实现了这些组件。\n",
    "\n",
    "在本节中，我们将介绍如何(**通过使用深度学习框架来简洁地实现**)\n",
    " :numref:`sec_linear_scratch`中的(**线性回归模型**)。\n",
    "\n",
    "## 生成数据集\n",
    "\n",
    "与 :numref:`sec_linear_scratch`中类似，我们首先[**生成数据集**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.Tensor([21,3])\n",
    "true_b = torch.Tensor([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(w,b,nums):\n",
    "    \"\"\"x*w+b\"\"\"\n",
    "    # x:(1000,2)\n",
    "    x = torch.normal(20,5,(nums,len(w)))\n",
    "    y = torch.mv(x,w) + b\n",
    "    y += torch.normal(0,0.01,y.shape)\n",
    "    # return x,y.reshape(-1,1)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,labels = generate_data(true_w,true_b,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[17.8932, 16.1795],\n",
       "         [16.9265, 19.1261]]),\n",
       " tensor([429.3050, 417.8419]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:2:],labels[:2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "我们可以[**调用框架中现有的API来读取数据**]。\n",
    "我们将`features`和`labels`作为API的参数传递，并通过数据迭代器指定`batch_size`。\n",
    "此外，布尔值`is_train`表示是否希望数据迭代器对象在每个迭代周期内打乱数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "使用`data_iter`的方式与我们在 :numref:`sec_linear_scratch`中使用`data_iter`函数的方式相同。为了验证是否正常工作，让我们读取并打印第一个小批量样本。\n",
    "与 :numref:`sec_linear_scratch`不同，这里我们使用`iter`构造Python迭代器，并使用`next`从迭代器中获取第一项。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(features,labels,batch_size,is_train=True):\n",
    "    data_set = data.TensorDataset(*(features,labels))\n",
    "    return data.DataLoader(dataset=data_set,batch_size=batch_size,shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = data_loader(features=features,labels=labels,batch_size=200,is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[20.0704, 11.7683],\n",
       "         [19.4642, 22.6963],\n",
       "         [28.3401, 16.5893],\n",
       "         [15.5100, 23.1295],\n",
       "         [22.9122, 17.5273],\n",
       "         [16.3307, 26.9738],\n",
       "         [29.3655, 18.3799],\n",
       "         [17.8175, 13.4989],\n",
       "         [24.0392, 15.9940],\n",
       "         [17.3502, 19.3529],\n",
       "         [ 9.3762, 20.5174],\n",
       "         [21.1559, 20.7953],\n",
       "         [22.4931, 26.4088],\n",
       "         [19.4117, 24.9643],\n",
       "         [22.2526, 22.2254],\n",
       "         [22.1231, 14.2236],\n",
       "         [23.0618, 22.0338],\n",
       "         [27.5717, 17.8021],\n",
       "         [16.8359, 14.9655],\n",
       "         [21.5565, 22.1211],\n",
       "         [26.0744, 21.6051],\n",
       "         [18.2624, 25.1664],\n",
       "         [12.7785, 21.8532],\n",
       "         [16.7640, 18.1033],\n",
       "         [23.2762, 23.1141],\n",
       "         [14.8007, 20.2382],\n",
       "         [13.2245, 15.7086],\n",
       "         [23.4634, 13.3742],\n",
       "         [26.9825, 31.3011],\n",
       "         [15.4322, 22.8175],\n",
       "         [14.0177, 18.3883],\n",
       "         [20.3211, 24.2741],\n",
       "         [20.7136, 12.0870],\n",
       "         [19.9049, 19.0384],\n",
       "         [17.7325, 19.4022],\n",
       "         [27.1515, 17.8203],\n",
       "         [13.9038, 30.5358],\n",
       "         [11.6857, 26.8624],\n",
       "         [19.4138, 19.8342],\n",
       "         [21.7329, 13.9073],\n",
       "         [15.6821, 17.6038],\n",
       "         [16.9266, 26.9079],\n",
       "         [13.0252, 27.2822],\n",
       "         [23.8470, 21.3134],\n",
       "         [20.7918, 21.7877],\n",
       "         [ 8.4277, 22.1094],\n",
       "         [14.9345, 27.4586],\n",
       "         [17.0125, 21.9223],\n",
       "         [11.2865, 22.9078],\n",
       "         [23.5049, 25.3537],\n",
       "         [20.7904, 23.6013],\n",
       "         [18.3199, 17.0470],\n",
       "         [17.1409, 23.3963],\n",
       "         [16.4656, 22.3117],\n",
       "         [20.2930, 24.6118],\n",
       "         [15.8015, 16.1180],\n",
       "         [22.3614, 20.8606],\n",
       "         [20.1427, 23.3282],\n",
       "         [10.2813,  9.8829],\n",
       "         [18.4472, 23.1305],\n",
       "         [17.1390, 10.7885],\n",
       "         [26.1249, 13.6251],\n",
       "         [19.5956, 16.8406],\n",
       "         [29.8104,  9.1612],\n",
       "         [27.2543, 16.9593],\n",
       "         [22.3499, 18.3918],\n",
       "         [14.8386, 17.5942],\n",
       "         [27.3749, 16.4728],\n",
       "         [23.4521, 35.1846],\n",
       "         [31.1097, 25.8237],\n",
       "         [22.4512, 19.8352],\n",
       "         [18.6063, 19.6195],\n",
       "         [19.7346, 25.5659],\n",
       "         [11.9832, 21.5372],\n",
       "         [18.6996, 21.8359],\n",
       "         [21.0149, 15.6239],\n",
       "         [21.5132, 17.8616],\n",
       "         [14.5924, 18.4425],\n",
       "         [13.7529, 17.8411],\n",
       "         [16.9815, 26.6581],\n",
       "         [25.2574, 20.2730],\n",
       "         [27.3630, 20.8979],\n",
       "         [23.5300, 13.5327],\n",
       "         [19.4967, 19.3952],\n",
       "         [16.8581, 21.0786],\n",
       "         [23.6008, 15.8883],\n",
       "         [16.1443, 20.6679],\n",
       "         [16.9004,  9.1812],\n",
       "         [29.3478, 14.6156],\n",
       "         [18.7144, 20.2634],\n",
       "         [12.9219, 16.6568],\n",
       "         [23.0019, 24.5943],\n",
       "         [13.4150, 16.0996],\n",
       "         [15.9314, 27.0670],\n",
       "         [17.2655, 24.5501],\n",
       "         [13.9902, 16.3487],\n",
       "         [25.1831, 16.2297],\n",
       "         [16.5132, 30.9320],\n",
       "         [17.3940, 20.8395],\n",
       "         [16.1083, 15.8369],\n",
       "         [32.4433, 20.5639],\n",
       "         [19.7138, 18.7372],\n",
       "         [29.6575, 20.3859],\n",
       "         [23.2962, 30.1580],\n",
       "         [25.6564, 22.2010],\n",
       "         [16.3345, 20.1339],\n",
       "         [19.8558, 21.1814],\n",
       "         [22.6272, 16.1834],\n",
       "         [21.2981, 13.4648],\n",
       "         [19.6985, 26.7488],\n",
       "         [17.4799, 18.7538],\n",
       "         [15.3930, 13.8076],\n",
       "         [15.6952, 19.4020],\n",
       "         [22.6294, 25.6643],\n",
       "         [18.4819, 13.0958],\n",
       "         [16.4968, 17.1499],\n",
       "         [27.3018, 18.2310],\n",
       "         [17.2964, 16.2146],\n",
       "         [19.9554, 22.2021],\n",
       "         [20.7566, 14.1882],\n",
       "         [25.2974, 20.5051],\n",
       "         [29.5016, 22.6442],\n",
       "         [15.5135, 23.3557],\n",
       "         [20.8959, 24.3738],\n",
       "         [ 7.2447, 14.0531],\n",
       "         [15.7727, 19.9146],\n",
       "         [11.9197, 27.9738],\n",
       "         [19.7557, 16.4101],\n",
       "         [17.9131, 19.9121],\n",
       "         [15.8258, 22.9350],\n",
       "         [17.3934, 26.9817],\n",
       "         [17.3528, 16.3598],\n",
       "         [20.6647, 15.0209],\n",
       "         [24.8577, 16.1538],\n",
       "         [16.7029, 11.3778],\n",
       "         [19.4522, 17.2300],\n",
       "         [15.2394, 16.5908],\n",
       "         [26.9874, 24.0579],\n",
       "         [22.2984, 19.7571],\n",
       "         [17.7559, 26.1158],\n",
       "         [24.1781, 22.7886],\n",
       "         [23.1505, 17.7189],\n",
       "         [16.3420, 13.5480],\n",
       "         [11.9981, 30.9812],\n",
       "         [17.6862, 22.5326],\n",
       "         [23.9980, 16.5038],\n",
       "         [24.1224, 12.2859],\n",
       "         [20.1268, 30.4798],\n",
       "         [14.3925, 19.1747],\n",
       "         [17.3099, 24.5355],\n",
       "         [22.5723, 15.2966],\n",
       "         [22.3471, 26.7707],\n",
       "         [20.3784, 20.9557],\n",
       "         [16.5937, 23.4925],\n",
       "         [15.8554, 23.8872],\n",
       "         [21.2372, 18.2701],\n",
       "         [22.5586, 23.4519],\n",
       "         [21.1166, 20.5446],\n",
       "         [19.0668, 14.5093],\n",
       "         [20.2487, 23.2513],\n",
       "         [11.4849, 23.4289],\n",
       "         [21.5461, 28.4240],\n",
       "         [23.0856, 12.7867],\n",
       "         [11.1093, 13.4962],\n",
       "         [13.1875, 23.9085],\n",
       "         [12.3787, 14.9883],\n",
       "         [22.2776, 24.2533],\n",
       "         [25.3100, 15.0308],\n",
       "         [27.0005, 14.9212],\n",
       "         [18.4019, 22.2048],\n",
       "         [31.6995, 26.5879],\n",
       "         [20.1463, 13.6763],\n",
       "         [26.3552, 13.8407],\n",
       "         [22.8091, 12.0106],\n",
       "         [20.7384, 21.3866],\n",
       "         [19.1467, 22.3339],\n",
       "         [21.9561, 21.8488],\n",
       "         [24.7822, 21.0520],\n",
       "         [20.2438, 19.5565],\n",
       "         [22.9724, 25.7747],\n",
       "         [24.9791, 26.3714],\n",
       "         [18.5466, 21.4092],\n",
       "         [14.1666, 27.5709],\n",
       "         [25.5505, 26.9848],\n",
       "         [23.2024, 17.5276],\n",
       "         [20.6695, 20.4569],\n",
       "         [24.1944, 16.8674],\n",
       "         [24.1993, 21.2834],\n",
       "         [21.7622, 24.2854],\n",
       "         [22.1023, 15.0902],\n",
       "         [25.6080, 19.1925],\n",
       "         [16.4181, 23.4845],\n",
       "         [28.1269, 18.6472],\n",
       "         [16.3169, 20.3962],\n",
       "         [19.8399, 21.1542],\n",
       "         [23.3942, 16.4614],\n",
       "         [11.1159, 24.9735],\n",
       "         [ 9.3416, 30.4307],\n",
       "         [22.1997, 21.9776],\n",
       "         [20.1298, 16.4771]]),\n",
       " tensor([461.7803, 481.8385, 649.9114, 400.0944, 538.7367, 428.8855, 676.8217,\n",
       "         419.6686, 557.7902, 427.4114, 263.4403, 511.6656, 556.5826, 487.5225,\n",
       "         538.9774, 512.2741, 555.4114, 637.4111, 403.4326, 524.0397, 617.3890,\n",
       "         464.0055, 338.9110, 411.3558, 563.1476, 376.5359, 329.8548, 537.8704,\n",
       "         665.5359, 397.5310, 354.5289, 504.5713, 476.2531, 480.1203, 435.5845,\n",
       "         628.6298, 388.5908, 330.9994, 472.1845, 503.1125, 387.1348, 441.1777,\n",
       "         360.3793, 569.7230, 506.9917, 248.3055, 400.9888, 428.0320, 310.7377,\n",
       "         574.6811, 512.4026, 440.8606, 435.1383, 417.7023, 505.0016, 385.1997,\n",
       "         537.1808, 497.9789, 250.5422, 461.7566, 397.2815, 594.5089, 467.0296,\n",
       "         658.4980, 628.2083, 529.5414, 369.3977, 629.2928, 603.0352, 735.7727,\n",
       "         535.9796, 454.5954, 496.1126, 321.2652, 463.1977, 493.1667, 510.3599,\n",
       "         366.7655, 347.3234, 441.5916, 596.2357, 642.3243, 539.7226, 472.6237,\n",
       "         422.2468, 548.2783, 406.0349, 387.4625, 665.1492, 458.7859, 326.3430,\n",
       "         561.8141, 335.0038, 420.7615, 441.2287, 347.8326, 582.5392, 444.5665,\n",
       "         432.8053, 390.7713, 747.9918, 475.2026, 688.9738, 584.6772, 610.3798,\n",
       "         408.4321, 485.5372, 528.7201, 492.6463, 498.9233, 428.3235, 369.6685,\n",
       "         392.8069, 557.2037, 432.4052, 402.8741, 633.0301, 416.8745, 490.6719,\n",
       "         483.4593, 597.7595, 692.4801, 400.8423, 516.9258, 199.2822, 395.9845,\n",
       "         339.2409, 469.1145, 440.8950, 406.1371, 451.2007, 418.4927, 484.0196,\n",
       "         575.4662, 389.8816, 465.1871, 374.7880, 643.9001, 532.5392, 456.2231,\n",
       "         581.1056, 544.3231, 388.8256, 349.9080, 444.0236, 558.4592, 548.4254,\n",
       "         519.1152, 364.7677, 442.1149, 524.9180, 554.5932, 495.8215, 423.9320,\n",
       "         409.6281, 505.7936, 549.0790, 510.0791, 448.9277, 499.9762, 316.4633,\n",
       "         542.7368, 528.1751, 278.7763, 353.6718, 309.9371, 545.6006, 581.6019,\n",
       "         616.7828, 458.0522, 750.4387, 469.1100, 599.9821, 519.9979, 504.6599,\n",
       "         474.0826, 531.6262, 588.5812, 488.7939, 564.7432, 608.7010, 458.6933,\n",
       "         385.2166, 622.5134, 544.8172, 500.4400, 563.6838, 577.0496, 534.8822,\n",
       "         514.3989, 600.3445, 420.2237, 651.6151, 408.8515, 485.0879, 545.6553,\n",
       "         313.3659, 292.4648, 537.1252, 477.1585])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## 定义模型\n",
    "\n",
    "当我们在 :numref:`sec_linear_scratch`中实现线性回归时，\n",
    "我们明确定义了模型参数变量，并编写了计算的代码，这样通过基本的线性代数运算得到输出。\n",
    "但是，如果模型变得更加复杂，且当你几乎每天都需要实现模型时，你会想简化这个过程。\n",
    "这种情况类似于为自己的博客从零开始编写网页。\n",
    "做一两次是有益的，但如果每个新博客你就花一个月的时间重新开始编写网页，那并不高效。\n",
    "\n",
    "对于标准深度学习模型，我们可以[**使用框架的预定义好的层**]。这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。\n",
    "我们首先定义一个模型变量`net`，它是一个`Sequential`类的实例。\n",
    "`Sequential`类将多个层串联在一起。\n",
    "当给定输入数据时，`Sequential`实例将数据传入到第一层，\n",
    "然后将第一层的输出作为第二层的输入，以此类推。\n",
    "在下面的例子中，我们的模型只包含一个层，因此实际上不需要`Sequential`。\n",
    "但是由于以后几乎所有的模型都是多层的，在这里使用`Sequential`会让你熟悉“标准的流水线”。\n",
    "\n",
    "回顾 :numref:`fig_single_neuron`中的单层网络架构，\n",
    "这一单层被称为*全连接层*（fully-connected layer），\n",
    "因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "在PyTorch中，全连接层在`Linear`类中定义。\n",
    "值得注意的是，我们将两个参数传递到`nn.Linear`中。\n",
    "第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# nn是神经网络的缩写\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "## (**初始化模型参数**)\n",
    "\n",
    "在使用`net`之前，我们需要初始化模型参数。\n",
    "如在线性回归模型中的权重和偏置。\n",
    "深度学习框架通常有预定义的方法来初始化参数。\n",
    "在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样，\n",
    "偏置参数将初始化为零。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "正如我们在构造`nn.Linear`时指定输入和输出尺寸一样，\n",
    "现在我们能直接访问参数以设定它们的初始值。\n",
    "我们通过`net[0]`选择网络中的第一个图层，\n",
    "然后使用`weight.data`和`bias.data`方法访问参数。\n",
    "我们还可以使用替换方法`normal_`和`fill_`来重写参数值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "## 定义损失函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**计算均方误差使用的是`MSELoss`类，也称为平方$L_2$范数**]。\n",
    "默认情况下，它返回所有样本损失的平均值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "## 定义优化算法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "小批量随机梯度下降算法是一种优化神经网络的标准工具，\n",
    "PyTorch在`optim`模块中实现了该算法的许多变种。\n",
    "当我们(**实例化一个`SGD`实例**)时，我们要指定优化的参数\n",
    "（可通过`net.parameters()`从我们的模型中获得）以及优化算法所需的超参数字典。\n",
    "小批量随机梯度下降只需要设置`lr`值，这里设置为0.03。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 43
   },
   "source": [
    "## 训练\n",
    "\n",
    "通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。\n",
    "我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。\n",
    "当我们需要更复杂的模型时，高级API的优势将大大增加。\n",
    "当我们有了所有的基本组件，[**训练过程代码与我们从零开始实现时所做的非常相似**]。\n",
    "\n",
    "回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（`train_data`），\n",
    "不停地从中获取一个小批量的输入和相应的标签。\n",
    "对于每一个小批量，我们会进行以下步骤:\n",
    "\n",
    "* 通过调用`net(X)`生成预测并计算损失`l`（前向传播）。\n",
    "* 通过进行反向传播来计算梯度。\n",
    "* 通过调用优化器来更新模型参数。\n",
    "\n",
    "为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(),lr=0.001)\n",
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)\n",
    "def train(epoch):\n",
    "    for e in range(epoch):\n",
    "        # features,labels\n",
    "        for feature,label in data_iter:\n",
    "            l = loss(net(feature),label)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        if e % 100 == 0 :\n",
    "            print(f\"loss: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jshen\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([200])) that is different to the input size (torch.Size([200, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26505.529296875\n",
      "loss: 17585.712890625\n",
      "loss: 16631.88671875\n",
      "loss: 14176.8544921875\n",
      "loss: 16257.9775390625\n",
      "loss: 14797.232421875\n",
      "loss: 16180.1533203125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\github\\d2l-zh-pytorch-colab\\03_chapter_linear-networks\\linear-regression-concise copy.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/github/d2l-zh-pytorch-colab/03_chapter_linear-networks/linear-regression-concise%20copy.ipynb#ch0000028?line=0'>1</a>\u001b[0m train(\u001b[39m1000\u001b[39;49m)\n",
      "\u001b[1;32md:\\github\\d2l-zh-pytorch-colab\\03_chapter_linear-networks\\linear-regression-concise copy.ipynb Cell 28'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github/d2l-zh-pytorch-colab/03_chapter_linear-networks/linear-regression-concise%20copy.ipynb#ch0000027?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(epoch):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github/d2l-zh-pytorch-colab/03_chapter_linear-networks/linear-regression-concise%20copy.ipynb#ch0000027?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github/d2l-zh-pytorch-colab/03_chapter_linear-networks/linear-regression-concise%20copy.ipynb#ch0000027?line=5'>6</a>\u001b[0m         \u001b[39m# features,labels\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/github/d2l-zh-pytorch-colab/03_chapter_linear-networks/linear-regression-concise%20copy.ipynb#ch0000027?line=6'>7</a>\u001b[0m         \u001b[39mfor\u001b[39;00m feature,label \u001b[39min\u001b[39;00m data_iter:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github/d2l-zh-pytorch-colab/03_chapter_linear-networks/linear-regression-concise%20copy.ipynb#ch0000027?line=7'>8</a>\u001b[0m             l \u001b[39m=\u001b[39m loss(net(feature),label)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github/d2l-zh-pytorch-colab/03_chapter_linear-networks/linear-regression-concise%20copy.ipynb#ch0000027?line=8'>9</a>\u001b[0m             trainer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\jshen\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jshen\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\jshen\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\jshen\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jshen\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jshen\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:138\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    136\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel)\n\u001b[0;32m    137\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m    139\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m    140\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    142\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21.0856,  3.0840]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input, model, device):\n",
    "  model.to(device)\n",
    "  with torch.no_grad():\n",
    "    input=input.to(device)\n",
    "    out = model(input)\n",
    "    # _, pre = torch.max(out.data, 1)\n",
    "    # return pre.item()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15.5672, 20.6116],\n",
       "         [20.8692, 19.7839],\n",
       "         [16.6927, 19.8733]]),\n",
       " tensor([[393.7514],\n",
       "         [502.5804],\n",
       "         [415.1509]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:3:],labels[:3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[393.4988],\n",
       "        [502.7402],\n",
       "        [414.9522]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(features[:3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[21.0856,  3.0840]]), tensor([1.6870]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data,net[0].bias.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features,test_labels = generate_data(true_w,true_b,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = net(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[449.5477],\n",
       "         [482.9488],\n",
       "         [574.4111]], grad_fn=<SliceBackward0>),\n",
       " tensor([[449.3329],\n",
       "         [483.3966],\n",
       "         [574.5920]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[:3:],test_labels[:3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4204, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(test_predict,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 51
   },
   "source": [
    "## 小结\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 53,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "* 我们可以使用PyTorch的高级API更简洁地实现模型。\n",
    "* 在PyTorch中，`data`模块提供了数据处理工具，`nn`模块定义了大量的神经网络层和常见损失函数。\n",
    "* 我们可以通过`_`结尾的方法将参数替换，从而初始化参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 55
   },
   "source": [
    "## 练习\n",
    "\n",
    "1. 如果将小批量的总损失替换为小批量损失的平均值，你需要如何更改学习率？\n",
    "1. 查看深度学习框架文档，它们提供了哪些损失函数和初始化方法？用Huber损失代替原损失，即\n",
    "    $$l(y,y') = \\begin{cases}|y-y'| -\\frac{\\sigma}{2} & \\text{ if } |y-y'| > \\sigma \\\\ \\frac{1}{2 \\sigma} (y-y')^2 & \\text{ 其它情况}\\end{cases}$$\n",
    "1. 你如何访问线性回归的梯度？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 57,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1781)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e1e609ed4275b16681bc4abde79d07778f26b9708257cdaa3e43b60c63d82f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
